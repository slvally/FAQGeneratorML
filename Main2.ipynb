{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qa_list = [\"What is Python?\", \"What are the benefits of using Python?\", \n",
    "#            \"How do I install Python?\", \"What is a Python module?\", \n",
    "#            \"What is a Python package?\", \"What is machine learning?\", \n",
    "#            \"How does machine learning work?\", \"What are the types of machine learning algorithms?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: kapan deadline terakhir pembayaran ukt?\n",
      "A: kapan terakhir bayar ukt?, deadline terakhir bayar ukt?\n",
      "\n",
      "Q: dimana saya dapat melakukan pembayaran ukt?\n",
      "A: dimana tempat pembayaran ukt?, dimana saya bisa membayar ukt?\n",
      "\n",
      "Q: dimana tempat pembayaran ukt?\n",
      "A: dimana saya dapat melakukan pembayaran ukt?, dedline pembayaran ukt?, tempat membayar ukt?, dimana tempat bayar ukt?\n",
      "\n",
      "Q: kapan terakhir bayar ukt?\n",
      "A: kapan deadline terakhir pembayaran ukt?, deadline terakhir bayar ukt?, dimana tempat bayar ukt?, bayar ukt dilakukan dimana?\n",
      "\n",
      "Q: dedline pembayaran ukt?\n",
      "A: dimana tempat pembayaran ukt?\n",
      "\n",
      "Q: deadline terakhir bayar ukt?\n",
      "A: kapan deadline terakhir pembayaran ukt?, kapan terakhir bayar ukt?, dimana tempat bayar ukt?, bayar ukt dilakukan dimana?\n",
      "\n",
      "Q: tempat membayar ukt?\n",
      "A: dimana tempat pembayaran ukt?, dimana saya bisa membayar ukt?, dimana tempat bayar ukt?\n",
      "\n",
      "Q: dimana saya bisa membayar ukt?\n",
      "A: dimana saya dapat melakukan pembayaran ukt?, tempat membayar ukt?\n",
      "\n",
      "Q: apakah ukt murah?\n",
      "A: apakah ukt mahal?\n",
      "\n",
      "Q: apakah ukt mahal?\n",
      "A: apakah ukt murah?\n",
      "\n",
      "Q: berapa angka ukt tahun ini?\n",
      "A: \n",
      "\n",
      "Q: dimana tempat bayar ukt?\n",
      "A: dimana tempat pembayaran ukt?, kapan terakhir bayar ukt?, deadline terakhir bayar ukt?, tempat membayar ukt?, bayar ukt dilakukan dimana?\n",
      "\n",
      "Q: bayar ukt dilakukan dimana?\n",
      "A: kapan terakhir bayar ukt?, deadline terakhir bayar ukt?, dimana tempat bayar ukt?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load data record of questions\n",
    "df = pd.read_csv('data.csv', encoding='utf-8')\n",
    "\n",
    "# Preprocess questions\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(df['Question'])\n",
    "\n",
    "# Compute similarity between questions\n",
    "similarity_matrix = cosine_similarity(X)\n",
    "\n",
    "# Set a threshold for similarity score\n",
    "threshold = 0.3\n",
    "\n",
    "# Create an empty dictionary to store FAQ\n",
    "faq = {}\n",
    "\n",
    "# Loop through each question\n",
    "for i in range(len(df)):\n",
    "    # Check if the question has already been added to FAQ\n",
    "    if df['Question'][i] not in faq:\n",
    "        # Get the similarity scores of the question to all other questions\n",
    "        sim_scores = similarity_matrix[i]\n",
    "        # Find the most similar question(s) with a score greater than the threshold\n",
    "        similar_questions = [df['Question'][j] for j in range(len(df)) if sim_scores[j] > threshold and i != j]\n",
    "        # Add the question and its most similar question(s) to FAQ\n",
    "        faq[df['Question'][i]] = similar_questions\n",
    "\n",
    "# Print the generated FAQ\n",
    "for question, similar_questions in faq.items():\n",
    "    print(f\"Q: {question}\")\n",
    "    print(f\"A: {', '.join(similar_questions)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 21)\t0.20805350721413685\n",
      "  (0, 16)\t0.42226943805445233\n",
      "  (0, 20)\t0.4686952365175914\n",
      "  (0, 6)\t0.5285485006538158\n",
      "  (0, 11)\t0.5285485006538158\n",
      "  (1, 13)\t0.5180035221571283\n",
      "  (1, 5)\t0.5180035221571283\n",
      "  (1, 17)\t0.4467072695612361\n",
      "  (1, 9)\t0.32482552071751297\n",
      "  (1, 21)\t0.1758381946317135\n",
      "  (1, 16)\t0.3568846141066054\n",
      "  (2, 19)\t0.6107133481613479\n",
      "  (2, 9)\t0.5007936818678592\n",
      "  (2, 21)\t0.27109525356289327\n",
      "  (2, 16)\t0.5502201905368977\n",
      "  (3, 2)\t0.49742948911292073\n",
      "  (3, 21)\t0.24508510556317836\n",
      "  (3, 20)\t0.5521186499425064\n",
      "  (3, 11)\t0.6226252410379849\n",
      "  (4, 7)\t0.793077252167631\n",
      "  (4, 21)\t0.2692129807224273\n",
      "  (4, 16)\t0.5463998930314553\n",
      "  (5, 2)\t0.49742948911292073\n",
      "  (5, 21)\t0.24508510556317836\n",
      "  (5, 20)\t0.5521186499425064\n",
      "  :\t:\n",
      "  (6, 21)\t0.2825174171032861\n",
      "  (7, 4)\t0.5777558680361232\n",
      "  (7, 14)\t0.4982355046711662\n",
      "  (7, 17)\t0.4982355046711662\n",
      "  (7, 9)\t0.36229454560640173\n",
      "  (7, 21)\t0.19612134749642532\n",
      "  (8, 15)\t0.7334526076416428\n",
      "  (8, 1)\t0.6325026716957008\n",
      "  (8, 21)\t0.24897317655015525\n",
      "  (9, 12)\t0.7334526076416428\n",
      "  (9, 1)\t0.6325026716957008\n",
      "  (9, 21)\t0.24897317655015525\n",
      "  (10, 10)\t0.49295015477870097\n",
      "  (10, 18)\t0.49295015477870097\n",
      "  (10, 0)\t0.49295015477870097\n",
      "  (10, 3)\t0.49295015477870097\n",
      "  (10, 21)\t0.16733373722778982\n",
      "  (11, 2)\t0.5502201905368979\n",
      "  (11, 19)\t0.610713348161348\n",
      "  (11, 9)\t0.5007936818678592\n",
      "  (11, 21)\t0.2710952535628933\n",
      "  (12, 8)\t0.7101104354301621\n",
      "  (12, 2)\t0.4892389296239064\n",
      "  (12, 9)\t0.44529039299770357\n",
      "  (12, 21)\t0.2410495906190073\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.cluster import KMeans\n",
    "\n",
    "# # Load data record of questions\n",
    "# df = pd.read_csv('data.csv', encoding='utf-8')\n",
    "\n",
    "# # Preprocess questions\n",
    "# vectorizer = TfidfVectorizer(stop_words='english')\n",
    "# X = vectorizer.fit_transform(df['Question'])\n",
    "# print(X)\n",
    "\n",
    "# # Cluster questions\n",
    "# kmeans = KMeans(n_clusters=4, random_state=0)\n",
    "# kmeans.fit(X)\n",
    "\n",
    "# # Add cluster labels to data record\n",
    "# df['Cluster'] = kmeans.labels_\n",
    "\n",
    "# # Print clusters\n",
    "# for cluster in sorted(df['Cluster'].unique()):\n",
    "#     print(f\"Cluster {cluster}:\")\n",
    "#     for question in df[df['Cluster'] == cluster]['Question']:\n",
    "#         print(f\"- {question}\")\n",
    "#     print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<13x22 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 53 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# Preprocess the data\n",
    "# stop_words = set(stopwords.words('indonesia'))\n",
    "# stop_words = {'halo', 'selamat', 'pagi', 'siang', 'sore', 'malam'}\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# def preprocess_text(text):\n",
    "#     # Tokenize the text\n",
    "#     tokens = word_tokenize(text.lower())\n",
    "    \n",
    "#     # Remove stop words and lemmatize the words\n",
    "#     lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]\n",
    "    \n",
    "#     # Join the tokens back into a single string\n",
    "#     return ' '.join(lemmatized_tokens)\n",
    "\n",
    "df['processed_text'] = df['Question']\n",
    "\n",
    "# Extract features\n",
    "tfidf = TfidfVectorizer(lowercase=True)\n",
    "X = tfidf.fit_transform(df['processed_text'])\n",
    "\n",
    "print(X)\n",
    "\n",
    "# # Cluster the data \n",
    "# kmeans = KMeans(n_clusters=2, random_state=0)\n",
    "# kmeans.fit(X)\n",
    "# # kmeans.labels_\n",
    "# # kmeans.cluster_centers_\n",
    "\n",
    "# # Evaluate the clusters\n",
    "# wss = kmeans.inertia_\n",
    "# silhouette = silhouette_score(X, kmeans.labels_)\n",
    "\n",
    "# # Identify frequently asked questions\n",
    "# df['cluster'] = kmeans.labels_\n",
    "# n_top_questions = 2\n",
    "# for i in range(2):  # Assuming 5 clusters\n",
    "#     cluster_df = df[df['cluster'] == i]\n",
    "#     cluster_question_counts = cluster_df['Question'].value_counts()\n",
    "#     top_questions = cluster_question_counts[:n_top_questions].index.tolist()\n",
    "#     print(f\"Cluster {i}: {', '.join(top_questions)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
